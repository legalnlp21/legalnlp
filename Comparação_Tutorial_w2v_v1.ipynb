{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparação_Tutorial_w2v_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YH115ZDBOQMFlpXwJ71PWuBaEb6NfJKz",
      "authorship_tag": "ABX9TyOCPlg1NRXX1wefHvbwR5WJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/legalnlp21/legalnlp/blob/main/Compara%C3%A7%C3%A3o_Tutorial_w2v_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkzaEKDx7Agr"
      },
      "source": [
        "# Aplicando o Word2Vec em um dataset real\n",
        "\n",
        "Olá. Nesse tutorial vamos demonstrar como utilizar word-embeddings geradas a partir do método Word2Vec, em cima de um corpo de texto do meio jurídico.\n",
        "\n",
        "O método Word2Vec utiliza o contexto das palavras nos textos para gerar as embbedings. Para isso, foi utilizado o pacote *gensim* (versão 3.6.0), que integra as ferramentas necessárias para gerar, salvar e carregar as embbedings.\n",
        "\n",
        "As ferramentas de limpeza de texto usadas foram criadas com o enfoque em textos do meio jurídico, mas podem ser usadas com outros textos igualmente. \n",
        "\n",
        "Para o funcionamento correto, recomendamos que o usuário tenha acesso aos seguintes módulos:\n",
        "* ScikitLearn\n",
        "* Keras\n",
        "* Gensim\n",
        "* String\n",
        "* Numpy\n",
        "* Pandas\n",
        "* Ftfy\n",
        "\n",
        "Neste tutorial, faremos um modelo de Redes Neurais Convolucionais para classificar processos legais em \"Ativo\", \"Suspenso\" e \"Arquivado\". O dataset esta disponível\n",
        "[nesta página](https://www.kaggle.com/felipepolo/brazilian-legal-proceedings)\n",
        "do Kaggle. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC2UjjbL80ee"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8_955rB-sU7"
      },
      "source": [
        "De início, vamos importar as bibliotecas e funções que serão usadas adiante. Devemos também instalar as bibliotecas que não estão disponíveis por padrão no Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGFJlWE7-sEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b2b75e-7511-4868-8705-00117934bc00"
      },
      "source": [
        "!pip install gensim==3.8.1\n",
        "!pip install ftfy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from gensim.models import KeyedVectors\n",
        "from string import punctuation\n",
        "from os import listdir\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from clean_functions import *\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim==3.8.1 in /usr/local/lib/python3.7/dist-packages (3.8.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (5.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.19.5)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.0.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHOhgv8n7GjM"
      },
      "source": [
        "## Carregando os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4IIaMWG_xD5"
      },
      "source": [
        "Nosso dataset esta em formato *json*. Para ficar em um formato mais conveniente, vamos transpor o dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9XaBkiF6LAe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1a293a3a-21e6-4544-e5e1-e7cb3f8fb2b0"
      },
      "source": [
        "df = pd.read_json(\"/content/drive/MyDrive/Demos/labeled.json\").transpose()\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>H:Arquivado</td>\n",
              "      <td>{'-1': 'Tipo do Movimento:Ato Ordinatório Prat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>H:Ativo</td>\n",
              "      <td>{'-1': 'Tipo do Movimento:Recebimento ', '-2':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>H:Ativo</td>\n",
              "      <td>{'-1': 'Tipo do Movimento:RemessaDestinatário:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>H:Arquivado</td>\n",
              "      <td>{'-1': 'Tipo do Movimento:Arquivamento Tipo de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>H:Arquivado</td>\n",
              "      <td>{'-1': 'Tipo do Movimento:Arquivamento Tipo de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         label                                              texts\n",
              "0  H:Arquivado  {'-1': 'Tipo do Movimento:Ato Ordinatório Prat...\n",
              "1      H:Ativo  {'-1': 'Tipo do Movimento:Recebimento ', '-2':...\n",
              "2      H:Ativo  {'-1': 'Tipo do Movimento:RemessaDestinatário:...\n",
              "3  H:Arquivado  {'-1': 'Tipo do Movimento:Arquivamento Tipo de...\n",
              "4  H:Arquivado  {'-1': 'Tipo do Movimento:Arquivamento Tipo de..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05IL0rD1AtI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80f46a44-3eed-4e89-d0b3-cb533b634063"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6449, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVnNlojSAso9"
      },
      "source": [
        "O dataset é composto por um conjunto de 6449 processos classificados nas 3 categorias:\n",
        "* Ativo\n",
        "* Suspenso\n",
        "* Arquivado\n",
        "\n",
        "Para esse tutorial, iremos apenas utilizar os textos indexados com '-1'. Vamos usar a função \"clean\" em cada um dos textos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FHdqq-ABt8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e36f81-6cd5-4248-9987-15f30881db74"
      },
      "source": [
        "X_textos = df.texts[:].apply(lambda dict: clean(dict['-1']))\n",
        "\n",
        "X_textos.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    tipo do movimento : ato ordinatório praticado ...\n",
              "1                      tipo do movimento : recebimento\n",
              "2    tipo do movimento : remessadestinatário : trib...\n",
              "3    tipo do movimento : arquivamento tipo de arqui...\n",
              "4    tipo do movimento : arquivamento tipo de arqui...\n",
              "Name: texts, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k246rN0qCEK6"
      },
      "source": [
        "Agora faremos a separação das categorias da nossa target, numerando de 0 a 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXZDf4ZECWpJ"
      },
      "source": [
        "def converte_label(label):\n",
        "  if label == \"H:Ativo\": return 0\n",
        "  elif label == \"H:Suspenso\": return 1\n",
        "  else: return 2\n",
        "labels = array(df.label[:].apply(converte_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAIHkrlbCdZ0",
        "outputId": "a9f291ed-3294-4760-ab0f-c96617661e30"
      },
      "source": [
        "labels[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 0, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVib4BEqAiBI"
      },
      "source": [
        "Com isso feito, podemos tratar nossos dados para que a rede possa interpreta-los e trabalhar de forma adequada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS8Hn-G6C23H"
      },
      "source": [
        "## Preparando os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqsU1Ci4C7Ck"
      },
      "source": [
        "O dataset que estamos usando não precisou de muito tratamento. Para as próprias aplicações, o leitor deve verificar com cautela as peculiaridades dos dados, antes de realizar a tokenização."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJpdcmyzDVLQ"
      },
      "source": [
        "Com nossos textos tratados, vamos começar a prepará-los para serem recebidos pela rede neural. A estrutura basica da rede neural para NLP deve iniciar com uma camada chamada de \"embedding layer\". Essa camada é a responsável por traduzir as palavras para vetores. Ela fara isso a partir de uma matriz de pesos, onde cada i-ésima linha contém o vetor referente a i-ésima palavra.\n",
        "\n",
        "Portanto, devemos indexar cada palavra a um número inteiro, e representar nossos textos como vetores de indexação, ou seja, vetores com os números inteiros referentes a cada palavra. Para isso vamos tokenizar nosso corpo de texto utilizando o objeto *Tokenizer* do Keras. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbuxARSWEyH0",
        "outputId": "3df74073-199a-41e0-d880-c03cc32b7fec"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(X_textos)\n",
        "tamanho_vocab = len(t.word_index) + 1\n",
        "encoded_textos = array(t.texts_to_sequences(X_textos))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15II9RMjFK37",
        "outputId": "10aba8fd-95de-4519-8068-165e7de3fecb"
      },
      "source": [
        "t.index_word[8], t.index_word[4], t.index_word[39], t.index_word[59], t.index_word[120], t.index_word[185], \"...\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tipo', 'do', 'movimento', 'ato', 'ordinatório', 'praticado', '...')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AhStGQzFoqr",
        "outputId": "aeb8c53f-7850-4862-b73e-fa097627f307"
      },
      "source": [
        "print(encoded_textos[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 4, 39, 59, 120, 185, 138, 75, 36, 95, 94, 61, 168, 241, 462, 2, 80, 1, 45, 349, 528, 614, 212, 1414, 683, 1415, 36, 684, 685]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLM1bSciFz4q"
      },
      "source": [
        "Cada vetor agora representa um texto, contúdo, cada um pode ter tamanhos distintos. Devemos padroniza-los, completando os textos menores com \"0\" até que cheguem no tamanho do maior texto dos dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FHf-ZaBFRd_",
        "outputId": "1b2667f0-bfed-42a8-94ee-b741a3448e72"
      },
      "source": [
        "len_maior = 0\n",
        "for lista in encoded_textos:\n",
        "  if len(lista) > len_maior: len_maior = len(lista)\n",
        "\n",
        "len_maior"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "306"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7kn5y0cGgUa"
      },
      "source": [
        "Vamos usar a função \"pad_sequences\" do Keras para ajustar o tamanho dos textos para 306. Além disso, é recomendável que passemos os índices para \"float\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEucvRdpGfOd",
        "outputId": "5ba8c163-0f53-4eea-cc34-084f466753e0"
      },
      "source": [
        "padded_docs = pad_sequences(encoded_textos, maxlen=len_maior, padding='post').astype('float32')\n",
        "\n",
        "len(padded_docs[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "306"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSk6jJdyHOxZ"
      },
      "source": [
        "Nossos textos estão prontos para serem recebidos pela rede neural, contudo, ainda é necessário gerar a camada de embbeding da rede. Faremos isso na próxima seção."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OBPiQ8FHe45"
      },
      "source": [
        "Também devemos tratar o nosso vetor de categorias. Por padrão, nossa target deve estar em formato matricial, com 1 na coluna representante da categoria do texto daquela linha e 0 nas demais.\n",
        "\n",
        "Vamos usar o objeto \"OneHotEncoder\" do ScikitLearn e passar a matriz para a forma densa (objeto retorna na forma de matriz esparça). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT3xnkJzG3cr",
        "outputId": "24891894-de27-400c-b8a3-bb3b8bb17d82"
      },
      "source": [
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "label_onehot = encoder.fit_transform(labels.reshape((-1,1))).todense()\n",
        "\n",
        "label_onehot[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 1.],\n",
              "        [1., 0., 0.],\n",
              "        [1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwODax6gJYJj"
      },
      "source": [
        "Agora, com nossos dados preparados, começaremos a cuidar da \"embbeding layer\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF2KqXCSJp8r"
      },
      "source": [
        "## Preparando as embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65HTRJhl4fyR"
      },
      "source": [
        "Primeiramente, vamos importar o modelo Word2Vec treinado. Este modelo tem suas embbedings de tamanho 100 e foi treinado usando uma janela de tamanho 15 e \"epochs\" = 20. Vamos usar o objeto KeyedVectors do *Gensim* para carregar o model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lBSWXyyImRP"
      },
      "source": [
        "model = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/Demos/cbow_s100.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyEM3_ZQ5sBD"
      },
      "source": [
        "Com o modelo carregado, já podemos estruturar a matriz de pesos. Neste caso específico, todas as palavras do corpo de texto dos dados estão contidas no vocabulário do modelo Word2Vec, contudo, o leitor deve ter o cuidado de tratar os casos em que essa equivalência não aconteça."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--X1RePT68GN"
      },
      "source": [
        "Vamos estruturar um dicionário, no qual cada chave é uma palavra do corpo do vocabulário do modelo e cada valor representa sua embbeding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mipcv8F47jeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86087094-a8b7-4b89-9ca8-779185d0abf0"
      },
      "source": [
        "wv_dict = dict(zip(model.wv.index2word[:], model.wv.vectors[:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCQs9j3c7mWv"
      },
      "source": [
        "Para acelerar o treino da rede, e diminuir o tamanho da matriz de pesos, podemos fazer um dicionário somente com as palavras do texto, pois geralmente, o vocabulário do modelo Word2Vec é muito mais extenso que o necessário. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv8iy2OF8SrV"
      },
      "source": [
        "wv_dict_updated = {}\n",
        "for palavra in t.index_word.values():\n",
        "  if palavra in wv_dict.keys():\n",
        "    wv_dict_updated[palavra] = wv_dict[palavra]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10p1dF1F6n28"
      },
      "source": [
        "Por fim, podemos estruturar a matriz de pesos, colocando a palavra de i-ésimo índice na i-ésima linha da matriz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnopJgYe8rEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3f33e9-2062-460a-e612-4439cb501c4b"
      },
      "source": [
        "matriz_de_pesos = zeros((tamanho_vocab, 100))\n",
        "for palavra, i in t.word_index.items():\n",
        "  vetor_embed =  wv_dict_updated.get(palavra)\n",
        "  if vetor_embed is not None:\n",
        "    matriz_de_pesos[i] = vetor_embed\n",
        "\n",
        "matriz_de_pesos.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2827, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLn_LSKJ9SPb"
      },
      "source": [
        "## Treinando o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n7XjYRB9jSN"
      },
      "source": [
        "Com nossos dados codificados, e nossa matriz de pesos pronta, podemos começar a estruturar nossa Rede Neural. Nosso modelo será uma Rede Neural Convolucional, ou seja, aplicaremos uma camada de filtragem e em seguida uma camada de pooling, buscando ressaltar informações importantes das embbedings. \n",
        "\n",
        "Nossa rede terá a seguinte estrutura:\n",
        "1. A primeira camada de embbeding, que fara a codificação das palavras (representadas como índices) nos seus respectivos vetores.\n",
        "2. A segunda será uma camada convolucional, com 128 filtros no output, kernel de tamanho 5 e função de ativação 'ReLU'.\n",
        "3. A terceira camada será a MaxPooling de tamanho 2.\n",
        "4. Como o output da 3ª camada é um tensor, a quarta camada será uma camada de \"achatamento\".\n",
        "5. Por fim, a camada do output, de tamanho 3 e função de ativação *softmax*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlub9n_C9R3L"
      },
      "source": [
        "emb = Embedding(tamanho_vocab, 100, weights = [matriz_de_pesos], input_length=len_maior, trainable = False)\n",
        "\n",
        "rede = Sequential()\n",
        "\n",
        "rede.add(emb)\n",
        "rede.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "rede.add(MaxPooling1D(pool_size=2))\n",
        "rede.add(Flatten())\n",
        "rede.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-Sa_0gSAXIe"
      },
      "source": [
        "Para terminar a estrutura da rede, vamos usar a função perda como 'categorical_crossentropy', o caso categórico da entropia cruzda, para o otimizador ultilizaremos o 'adam' e a métrica de avaliação será a acurácia. Podemos ver a arquitetura utilizando o método \"*Sequential().summary()*\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6YSMgojBGcz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6dda44-3376-42c3-d741-6894a9376cab"
      },
      "source": [
        "rede.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(rede.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 306, 100)          282700    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 302, 128)          64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 151, 128)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 19328)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 57987     \n",
            "=================================================================\n",
            "Total params: 404,815\n",
            "Trainable params: 122,115\n",
            "Non-trainable params: 282,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bWrwUvwBOne"
      },
      "source": [
        "Vamos separar nossos dados em dados de treino e teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Elh0HQwBOOw"
      },
      "source": [
        "n = 4500\n",
        "X_treino, X_teste, Y_treino, Y_teste = train_test_split(padded_docs, label_onehot, random_state=42, train_size=0.7, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n64Ib0kxBYZS"
      },
      "source": [
        "Por fim, podemos treinar o modelo e verificar nossos resultados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qp3FHJoBIr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20176981-28d5-4eeb-fc43-a4c9b660328d"
      },
      "source": [
        "rede.fit(X_treino, Y_treino, epochs=50, validation_split=0.1, batch_size=500, verbose=1,  callbacks=[EarlyStopping(monitor='val_loss', patience=15)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 8s 779ms/step - loss: 0.9694 - accuracy: 0.5044 - val_loss: 0.8539 - val_accuracy: 0.6704\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 7s 731ms/step - loss: 0.7685 - accuracy: 0.6896 - val_loss: 0.7543 - val_accuracy: 0.7080\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 7s 734ms/step - loss: 0.6623 - accuracy: 0.7287 - val_loss: 0.6636 - val_accuracy: 0.7080\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 7s 732ms/step - loss: 0.6111 - accuracy: 0.7484 - val_loss: 0.6236 - val_accuracy: 0.7323\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 7s 746ms/step - loss: 0.5641 - accuracy: 0.7743 - val_loss: 0.5865 - val_accuracy: 0.7788\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 7s 738ms/step - loss: 0.5383 - accuracy: 0.7973 - val_loss: 0.5663 - val_accuracy: 0.7832\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 7s 739ms/step - loss: 0.4913 - accuracy: 0.8135 - val_loss: 0.5352 - val_accuracy: 0.7942\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 7s 734ms/step - loss: 0.4782 - accuracy: 0.8137 - val_loss: 0.5306 - val_accuracy: 0.7898\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 7s 726ms/step - loss: 0.4641 - accuracy: 0.8116 - val_loss: 0.4957 - val_accuracy: 0.7898\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 7s 736ms/step - loss: 0.4379 - accuracy: 0.8287 - val_loss: 0.4793 - val_accuracy: 0.8009\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 7s 741ms/step - loss: 0.4331 - accuracy: 0.8272 - val_loss: 0.4639 - val_accuracy: 0.8031\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 7s 739ms/step - loss: 0.3967 - accuracy: 0.8392 - val_loss: 0.4543 - val_accuracy: 0.8075\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 7s 742ms/step - loss: 0.3770 - accuracy: 0.8487 - val_loss: 0.4327 - val_accuracy: 0.8429\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 7s 741ms/step - loss: 0.3734 - accuracy: 0.8697 - val_loss: 0.4180 - val_accuracy: 0.8518\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 7s 735ms/step - loss: 0.3663 - accuracy: 0.8699 - val_loss: 0.4098 - val_accuracy: 0.8584\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 7s 726ms/step - loss: 0.3479 - accuracy: 0.8775 - val_loss: 0.4299 - val_accuracy: 0.8451\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 7s 730ms/step - loss: 0.3360 - accuracy: 0.8794 - val_loss: 0.4033 - val_accuracy: 0.8540\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 7s 726ms/step - loss: 0.3329 - accuracy: 0.8737 - val_loss: 0.4061 - val_accuracy: 0.8473\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 7s 728ms/step - loss: 0.3329 - accuracy: 0.8783 - val_loss: 0.4018 - val_accuracy: 0.8540\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 7s 730ms/step - loss: 0.3113 - accuracy: 0.8889 - val_loss: 0.3937 - val_accuracy: 0.8562\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 7s 738ms/step - loss: 0.3273 - accuracy: 0.8809 - val_loss: 0.3923 - val_accuracy: 0.8540\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 7s 736ms/step - loss: 0.3136 - accuracy: 0.8863 - val_loss: 0.3937 - val_accuracy: 0.8496\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 7s 738ms/step - loss: 0.3078 - accuracy: 0.8908 - val_loss: 0.3938 - val_accuracy: 0.8606\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 7s 740ms/step - loss: 0.3172 - accuracy: 0.8830 - val_loss: 0.3910 - val_accuracy: 0.8584\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 7s 741ms/step - loss: 0.3115 - accuracy: 0.8850 - val_loss: 0.3960 - val_accuracy: 0.8518\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 7s 742ms/step - loss: 0.3025 - accuracy: 0.8880 - val_loss: 0.3929 - val_accuracy: 0.8562\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 7s 733ms/step - loss: 0.2999 - accuracy: 0.8907 - val_loss: 0.3911 - val_accuracy: 0.8496\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 7s 735ms/step - loss: 0.2870 - accuracy: 0.8946 - val_loss: 0.3967 - val_accuracy: 0.8562\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 7s 734ms/step - loss: 0.3136 - accuracy: 0.8839 - val_loss: 0.4050 - val_accuracy: 0.8496\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 7s 721ms/step - loss: 0.2928 - accuracy: 0.8901 - val_loss: 0.3870 - val_accuracy: 0.8518\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 6s 712ms/step - loss: 0.2912 - accuracy: 0.8967 - val_loss: 0.3876 - val_accuracy: 0.8628\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 7s 719ms/step - loss: 0.2847 - accuracy: 0.8977 - val_loss: 0.3886 - val_accuracy: 0.8562\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 6s 708ms/step - loss: 0.2909 - accuracy: 0.8941 - val_loss: 0.3989 - val_accuracy: 0.8562\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 7s 719ms/step - loss: 0.2936 - accuracy: 0.8917 - val_loss: 0.3889 - val_accuracy: 0.8584\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 6s 713ms/step - loss: 0.2834 - accuracy: 0.8949 - val_loss: 0.3945 - val_accuracy: 0.8562\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 7s 723ms/step - loss: 0.2871 - accuracy: 0.8981 - val_loss: 0.3895 - val_accuracy: 0.8673\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 7s 729ms/step - loss: 0.2857 - accuracy: 0.8984 - val_loss: 0.3866 - val_accuracy: 0.8628\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 7s 728ms/step - loss: 0.2858 - accuracy: 0.8908 - val_loss: 0.4049 - val_accuracy: 0.8518\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 7s 730ms/step - loss: 0.2767 - accuracy: 0.8998 - val_loss: 0.3945 - val_accuracy: 0.8584\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 6s 714ms/step - loss: 0.2830 - accuracy: 0.8942 - val_loss: 0.3928 - val_accuracy: 0.8584\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 7s 748ms/step - loss: 0.2755 - accuracy: 0.8962 - val_loss: 0.3980 - val_accuracy: 0.8606\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 7s 743ms/step - loss: 0.2763 - accuracy: 0.9001 - val_loss: 0.4033 - val_accuracy: 0.8518\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 7s 739ms/step - loss: 0.2699 - accuracy: 0.8933 - val_loss: 0.3978 - val_accuracy: 0.8540\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 7s 734ms/step - loss: 0.2763 - accuracy: 0.8949 - val_loss: 0.3952 - val_accuracy: 0.8584\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 7s 732ms/step - loss: 0.2805 - accuracy: 0.8946 - val_loss: 0.4068 - val_accuracy: 0.8540\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 7s 745ms/step - loss: 0.2745 - accuracy: 0.8951 - val_loss: 0.3998 - val_accuracy: 0.8496\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 7s 745ms/step - loss: 0.2720 - accuracy: 0.9009 - val_loss: 0.4106 - val_accuracy: 0.8496\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 7s 751ms/step - loss: 0.2857 - accuracy: 0.8929 - val_loss: 0.4219 - val_accuracy: 0.8496\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 7s 746ms/step - loss: 0.2806 - accuracy: 0.8950 - val_loss: 0.4092 - val_accuracy: 0.8518\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 7s 743ms/step - loss: 0.2688 - accuracy: 0.8969 - val_loss: 0.3966 - val_accuracy: 0.8606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf461b57d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek2GUT_nBiG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185b11a5-dd8b-4404-97cc-813c9245fe30"
      },
      "source": [
        "loss, acc_treino = rede.evaluate(X_treino, Y_treino, verbose=0)\n",
        "loss2, acc_teste = rede.evaluate(X_teste, Y_teste, verbose=0)\n",
        "print(f'Acurácia no treino: {round(acc_treino*100, 2)}%')\n",
        "print(f'Acurácia no teste: {round(acc_teste*100, 2)}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia no treino: 89.48%\n",
            "Acurácia no teste: 84.34%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T61i5sg5Da1g"
      },
      "source": [
        "predict = rede.predict(X_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQaVNmuzAYBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aeb3403-5ddd-4924-9197-e5b90c175513"
      },
      "source": [
        "Y_teste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1., 0., 0.],\n",
              "        [1., 0., 0.],\n",
              "        [1., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 1.],\n",
              "        [0., 0., 1.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFdq0E3w_Gp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589af577-bddd-4eeb-fd90-23d5ec7cbf30"
      },
      "source": [
        "predict1 = np.argmax(predict, axis=1)\n",
        "\n",
        "Y_teste1 = np.argmax(Y_teste, axis=1)\n",
        "np.array(Y_teste1.reshape(1,-1))[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9U9RC7H8q6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41fe1d77-dd4d-43a8-f3c7-c0db4f754787"
      },
      "source": [
        "print(classification_report(Y_teste1, predict1, labels=[0,1,2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86       901\n",
            "           1       0.86      0.55      0.67       140\n",
            "           2       0.86      0.85      0.85       894\n",
            "\n",
            "    accuracy                           0.84      1935\n",
            "   macro avg       0.85      0.76      0.79      1935\n",
            "weighted avg       0.84      0.84      0.84      1935\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbKfb8S8EiMZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cb1b38a6-212f-4dda-9d24-1d1dd8df8f18"
      },
      "source": [
        "cm = confusion_matrix(Y_teste1, predict1)\n",
        "sns.heatmap(cm , fmt=\".3g\", annot= True, cmap=\"Greens\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaFItkMbBhPF"
      },
      "source": [
        "Como a distância entre o score de treino e teste não é tão grande, e ambos performaram bem, podemos dizer que nosso modelo teve uma boa performance no geral. \n",
        "\n",
        "Uma analise mais aprofundada nos dados e na arquitetura da rede poderia levar a performances ainda melhores. Essas análises no entanto fogem do escopo deste tutorial, contudo, encorajamos o leitor a elaborar modelos que performem ainda melhor, e a realizar uma análise e engenharia de dados ainda mais aprofundada. \n",
        "\n",
        "Esperamos ter ajudado. \n",
        "\n",
        ":D"
      ]
    }
  ]
}