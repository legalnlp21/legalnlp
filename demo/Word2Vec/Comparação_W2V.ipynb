{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparação_W2V.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bChBWJCpV3AKzLjhSkAWsnA8T9i65HGb",
      "authorship_tag": "ABX9TyNw/A0qqKg3SlkyR1BDLAEM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/legalnlp21/legalnlp/blob/main/demo/Word2Vec/Compara%C3%A7%C3%A3o_W2V.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkzaEKDx7Agr"
      },
      "source": [
        "# Aplicando o Word2Vec em um dataset para classificação\n",
        "\n",
        "Nesse tutorial vamos demonstrar como utilizar word-embeddings geradas a partir do método Word2Vec, em cima de um corpo de texto, para classificação.\n",
        "\n",
        "O método Word2Vec utiliza o contexto das palavras nos textos para gerar as embbedings. Para isso, foi utilizado o pacote *gensim* (versão 3.8.1), que integra as ferramentas necessárias para gerar, salvar e carregar as embbedings.\n",
        "\n",
        "As ferramentas de limpeza de texto usadas foram criadas com o enfoque em textos do meio jurídico, mas podem ser usadas com outros textos igualmente. \n",
        "\n",
        "Para o funcionamento correto, recomendamos que o usuário tenha acesso aos seguintes módulos:\n",
        "* ScikitLearn\n",
        "* Keras\n",
        "* Gensim\n",
        "* String\n",
        "* Numpy\n",
        "* Pandas\n",
        "* Ftfy\n",
        "\n",
        "Neste tutorial, utilizamos um modelo de Redes Neurais Convolucionais para classificar processos legais em \"Ativo\", \"Suspenso\" e \"Arquivado\". O dataset esta disponível\n",
        "[nesta página](https://www.kaggle.com/felipepolo/brazilian-legal-proceedings)\n",
        "do Kaggle. \\\\\n",
        "Este turorial foi baseados nos seguintes artigos \n",
        "[[3]](https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/), [[4]](https://machinelearningmastery.com/best-practices-document-classification-deep-learning/) e [[5]](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n75Nw-K8NvZg"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install gensim==3.8.1\n",
        "!pip install git+https://github.com/legalnlp21/legalnlp\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRcf8sltNwbA"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC2UjjbL80ee"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8_955rB-sU7"
      },
      "source": [
        "De início, vamos importar as bibliotecas e funções que serão usadas adiante. Devemos também instalar as bibliotecas que não estão disponíveis por padrão no Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGFJlWE7-sEO"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from string import punctuation\n",
        "\n",
        "from os import listdir\n",
        "\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from legalnlp.clean_functions import *\n",
        "from legalnlp.get_premodel import get_premodel\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQB-oqeIJP0R",
        "outputId": "a30cd564-d0f7-445b-da48-ed0df706be10"
      },
      "source": [
        "# Downloading pre-trained model\n",
        "get_premodel('w2vnilc')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evk3pY5PdfpJ"
      },
      "source": [
        "model = KeyedVectors.load_word2vec_format('/content/cbow_s100/cbow_s100.txt')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHOhgv8n7GjM"
      },
      "source": [
        "## Carregando os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4IIaMWG_xD5"
      },
      "source": [
        "Vamos carregar a base de dados, que esta em formato *csv*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "G9XaBkiF6LAe",
        "outputId": "d05fce5a-d4f5-4e55-c3e8-51ccee5fade3"
      },
      "source": [
        "df=pd.read_csv('https://raw.githubusercontent.com/legalnlp21/legalnlp/main/demo/data_base.csv')\n",
        "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Início da Execução Juntado 0008003-11.2018.8.2...</td>\n",
              "      <td>H:Suspenso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ofício Requisitório - Comunicação - Protocolo ...</td>\n",
              "      <td>H:Arquivado</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arquivado Provisoriamente aguardando manifestação</td>\n",
              "      <td>H:Suspenso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Petição Juntada Juntada a petição diversa - Ti...</td>\n",
              "      <td>H:Ativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Remetidos os Autos para o Arquivo Geral – Devo...</td>\n",
              "      <td>H:Arquivado</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text        label\n",
              "0  Início da Execução Juntado 0008003-11.2018.8.2...   H:Suspenso\n",
              "1  Ofício Requisitório - Comunicação - Protocolo ...  H:Arquivado\n",
              "2  Arquivado Provisoriamente aguardando manifestação   H:Suspenso\n",
              "3  Petição Juntada Juntada a petição diversa - Ti...      H:Ativo\n",
              "4  Remetidos os Autos para o Arquivo Geral – Devo...  H:Arquivado"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05IL0rD1AtI7",
        "outputId": "279e776c-d952-4779-8987-fcfca826c0cc"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6449, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVnNlojSAso9"
      },
      "source": [
        "O dataset é composto por um conjunto de 6449 processos classificados nas 3 categorias:\n",
        "* Ativo\n",
        "* Suspenso\n",
        "* Arquivado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k246rN0qCEK6"
      },
      "source": [
        "Agora faremos a separação das categorias da nossa target, numerando de 0 a 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXZDf4ZECWpJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "e220fded-6e78-4991-e2f1-d1bb50a1dfb5"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(df['label'])\n",
        "df['encoded'] = encoder.transform(df['label'])\n",
        "df.drop(columns=['label'], inplace = True)\n",
        "df"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Início da Execução Juntado 0008003-11.2018.8.2...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ofício Requisitório - Comunicação - Protocolo ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arquivado Provisoriamente aguardando manifestação</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Petição Juntada Juntada a petição diversa - Ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Remetidos os Autos para o Arquivo Geral – Devo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6444</th>\n",
              "      <td>Remetidos os Autos para o Arquivo Geral – Devo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6445</th>\n",
              "      <td>Certidão de Trânsito em Julgado com Baixa Expe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6446</th>\n",
              "      <td>Petição Juntada Nº Protocolo: WSCB.19.70085805...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6447</th>\n",
              "      <td>Remetidos os Autos para o Tribunal de Justiça/...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6448</th>\n",
              "      <td>Arquivado Definitivamente</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6449 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  encoded\n",
              "0     Início da Execução Juntado 0008003-11.2018.8.2...        2\n",
              "1     Ofício Requisitório - Comunicação - Protocolo ...        0\n",
              "2     Arquivado Provisoriamente aguardando manifestação        2\n",
              "3     Petição Juntada Juntada a petição diversa - Ti...        1\n",
              "4     Remetidos os Autos para o Arquivo Geral – Devo...        0\n",
              "...                                                 ...      ...\n",
              "6444  Remetidos os Autos para o Arquivo Geral – Devo...        2\n",
              "6445  Certidão de Trânsito em Julgado com Baixa Expe...        0\n",
              "6446  Petição Juntada Nº Protocolo: WSCB.19.70085805...        1\n",
              "6447  Remetidos os Autos para o Tribunal de Justiça/...        1\n",
              "6448                          Arquivado Definitivamente        0\n",
              "\n",
              "[6449 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q60fpei5Q1o9",
        "outputId": "9bd67c49-afcb-48da-efb5-849b6d6c14c8"
      },
      "source": [
        "X_textos = df['text'].apply(clean)\n",
        "X_textos.head(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    início da execução juntado [processo] - - cump...\n",
              "1    ofício requisitório - - comunicação - - protoc...\n",
              "2    arquivado provisoriamente aguardando manifestação\n",
              "3    petição juntada juntada a petição diversa - - ...\n",
              "4    remetidos os autos para o arquivo geral – devo...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAIHkrlbCdZ0",
        "outputId": "0a182c08-0aaa-4385-df74-b2e0fd6032fb"
      },
      "source": [
        "labels = np.array(df['encoded'])\n",
        "labels[:5]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVib4BEqAiBI"
      },
      "source": [
        "Com isso feito, podemos tratar nossos dados para que a rede possa interpreta-los e trabalhar de forma adequada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS8Hn-G6C23H"
      },
      "source": [
        "## Preparando os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqsU1Ci4C7Ck"
      },
      "source": [
        "O dataset que estamos usando não precisou de muito tratamento. Para as próprias aplicações, o leitor deve verificar com cautela as peculiaridades dos dados, antes de realizar a tokenização."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJpdcmyzDVLQ"
      },
      "source": [
        "Com nossos textos tratados, vamos começar a prepará-los para serem recebidos pela rede neural. A estrutura basica da rede neural para NLP deve iniciar com uma camada chamada de \"embedding layer\". Essa camada é a responsável por traduzir as palavras para vetores. Ela fara isso a partir de uma matriz de pesos, onde cada i-ésima linha contém o vetor referente a i-ésima palavra.\n",
        "\n",
        "Portanto, devemos indexar cada tokem a um número natural, e representar nossos textos como vetores de indexação, ou seja, vetores com os números inteiros referentes a cada palavra. Para isso vamos tokenizar nosso corpo de texto utilizando o objeto *Tokenizer* do Keras. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbuxARSWEyH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9348674e-ddae-4ce3-c0bd-3ad06cda0df0"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(X_textos)\n",
        "tamanho_vocab = len(t.word_index) + 1\n",
        "encoded_textos = array(t.texts_to_sequences(X_textos))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15II9RMjFK37",
        "outputId": "ff99a4bb-4202-4efe-c7e1-ed50285c6e87"
      },
      "source": [
        "t.index_word[122], t.index_word[5], t.index_word[69], t.index_word[59], t.index_word[34], t.index_word[76], \"...\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('início', 'da', 'execução', 'juntado', 'processo', 'cumprimento', '...')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AhStGQzFoqr",
        "outputId": "7d9d41e7-bb6c-4124-ab34-bd29e77da6ad"
      },
      "source": [
        "print(encoded_textos[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[122, 5, 69, 59, 34, 76, 2, 56]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLM1bSciFz4q"
      },
      "source": [
        "Cada vetor agora representa um texto, contúdo, cada um pode ter tamanhos distintos. Devemos padroniza-los, aplicando *zero-padding.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FHf-ZaBFRd_",
        "outputId": "a9b61e90-7d1e-4bb0-e613-0708b8b442c5"
      },
      "source": [
        "len_maior = 0\n",
        "for lista in encoded_textos:\n",
        "  if len(lista) > len_maior: len_maior = len(lista)\n",
        "\n",
        "len_maior"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "306"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7kn5y0cGgUa"
      },
      "source": [
        "Vamos usar a função \"pad_sequences\" do Keras para ajustar o tamanho dos textos para 306. Além disso, é recomendável que passemos os índices para \"float\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEucvRdpGfOd",
        "outputId": "0b2e6bbc-a3ad-4323-892f-11304805d775"
      },
      "source": [
        "padded_docs = pad_sequences(encoded_textos, maxlen=len_maior, padding='post').astype('float32')\n",
        "\n",
        "len(padded_docs[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "306"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSk6jJdyHOxZ"
      },
      "source": [
        "Nossos textos estão prontos para serem recebidos pela rede neural, contudo, ainda é necessário gerar a camada de embbeding da rede. Faremos isso na próxima seção."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OBPiQ8FHe45"
      },
      "source": [
        "Também devemos tratar o nosso vetor de categorias. Por padrão, nossa target deve estar em formato matricial, com 1 na coluna representante da categoria do texto daquela linha e 0 nas demais.\n",
        "\n",
        "Vamos usar o objeto \"OneHotEncoder\" do ScikitLearn e passar a matriz para a forma densa (objeto retorna na forma de matriz esparça). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT3xnkJzG3cr",
        "outputId": "fee9dd54-58f0-4f8d-c32c-62dd982fd292"
      },
      "source": [
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "label_onehot = encoder.fit_transform(labels.reshape((-1,1))).todense()\n",
        "\n",
        "label_onehot[:3]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 1.],\n",
              "        [1., 0., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwODax6gJYJj"
      },
      "source": [
        "Agora, com nossos dados preparados, começaremos a cuidar da \"embbeding layer\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF2KqXCSJp8r"
      },
      "source": [
        "## Preparando as embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyEM3_ZQ5sBD"
      },
      "source": [
        "Com o modelo carregado, já podemos estruturar a matriz de pesos. Neste caso específico, todas as palavras do corpo de texto dos dados estão contidas no vocabulário do modelo Word2Vec, contudo, o leitor deve ter o cuidado de tratar os casos em que essa equivalência não aconteça."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--X1RePT68GN"
      },
      "source": [
        "Vamos estruturar um dicionário, no qual cada chave é uma palavra do corpo do vocabulário do modelo e cada valor representa sua embbeding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mipcv8F47jeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44056d1-da24-475e-c3f9-bcfda450d593"
      },
      "source": [
        "wv_dict = dict(zip(model.wv.index2word[:], model.wv.vectors[:]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCQs9j3c7mWv"
      },
      "source": [
        "Para acelerar o treino da rede, e diminuir o tamanho da matriz de pesos, podemos fazer um dicionário somente com as palavras do *corpus*, pois geralmente, o vocabulário do modelo *pre-trained Word2Vec* é muito mais extenso que o necessário. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv8iy2OF8SrV"
      },
      "source": [
        "wv_dict_updated = {}\n",
        "for palavra in t.index_word.values():\n",
        "  if palavra in wv_dict.keys():\n",
        "    wv_dict_updated[palavra] = wv_dict[palavra]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10p1dF1F6n28"
      },
      "source": [
        "Por fim, podemos estruturar a matriz de pesos, colocando a palavra de i-ésimo índice na i-ésima linha da matriz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnopJgYe8rEQ",
        "outputId": "07312c59-685d-4895-cf06-7108b952ccb6"
      },
      "source": [
        "matriz_de_pesos = zeros((tamanho_vocab, 100))\n",
        "for palavra, i in t.word_index.items():\n",
        "  vetor_embed =  wv_dict_updated.get(palavra)\n",
        "  if vetor_embed is not None:\n",
        "    matriz_de_pesos[i] = vetor_embed\n",
        "\n",
        "matriz_de_pesos.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2827, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLn_LSKJ9SPb"
      },
      "source": [
        "## Treinando o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n7XjYRB9jSN"
      },
      "source": [
        "Com nossos dados codificados, e nossa matriz de pesos pronta, podemos começar a estruturar nossa Rede Neural. Nosso modelo será uma Rede Neural Convolucional, ou seja, aplicaremos uma camada de filtragem e em seguida uma camada de *pooling*, buscando ressaltar informações importantes das *embbedings*. \n",
        "\n",
        "Nossa rede terá a seguinte estrutura:\n",
        "1. A primeira camada de *embbeding*, que fara a codificação das palavras (representadas como índices) nos seus respectivos vetores.\n",
        "2. A segunda será uma camada convolucional, com 128 filtros no output, *kernel* de tamanho 5 e função de ativação 'ReLU'.\n",
        "3. A terceira camada será a *MaxPooling* de tamanho 2.\n",
        "4. Como o output da 3ª camada é um tensor, a quarta camada será uma camada de \"achatamento\".\n",
        "5. Por fim, a camada do output, de tamanho 3 e função de ativação *softmax*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlub9n_C9R3L"
      },
      "source": [
        "emb = Embedding(tamanho_vocab, 100, weights = [matriz_de_pesos], input_length=len_maior, trainable = False)\n",
        "\n",
        "rede = Sequential()\n",
        "\n",
        "rede.add(emb)\n",
        "rede.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "rede.add(MaxPooling1D(pool_size=2))\n",
        "rede.add(Flatten())\n",
        "rede.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-Sa_0gSAXIe"
      },
      "source": [
        "Para terminar a estrutura da rede, vamos usar a função perda como 'categorical_crossentropy', o caso categórico da entropia cruzda, para o otimizador ultilizaremos o 'adam' e a métrica de avaliação será a acurácia. Podemos ver a arquitetura utilizando o método \"*Sequential().summary()*\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6YSMgojBGcz",
        "outputId": "3b8b8245-70d6-4a5d-d0aa-4df4611ca9fb"
      },
      "source": [
        "rede.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(rede.summary())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 306, 100)          282700    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 302, 128)          64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 151, 128)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 19328)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 57987     \n",
            "=================================================================\n",
            "Total params: 404,815\n",
            "Trainable params: 122,115\n",
            "Non-trainable params: 282,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bWrwUvwBOne"
      },
      "source": [
        "Vamos separar nossos dados em dados de treino e teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Elh0HQwBOOw"
      },
      "source": [
        "X_treino, X_teste, y_treino, y_teste = train_test_split(padded_docs, label_onehot, random_state=42, train_size=0.7, test_size=0.3)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n64Ib0kxBYZS"
      },
      "source": [
        "Por fim, podemos treinar o modelo e verificar nossos resultados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qp3FHJoBIr_",
        "outputId": "b9f42b55-edfe-415d-efcb-1424e3f8d0e8"
      },
      "source": [
        "rede.fit(X_treino, y_treino, epochs=50, validation_split=0.1, batch_size=500, verbose=1,  callbacks=[EarlyStopping(monitor='val_loss', patience=15)])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.9121 - accuracy: 0.5739 - val_loss: 0.7720 - val_accuracy: 0.7345\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.7628 - accuracy: 0.6962 - val_loss: 0.6878 - val_accuracy: 0.7389\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.6741 - accuracy: 0.7226 - val_loss: 0.6362 - val_accuracy: 0.7500\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.6226 - accuracy: 0.7393 - val_loss: 0.5866 - val_accuracy: 0.7765\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 9s 979ms/step - loss: 0.5831 - accuracy: 0.7706 - val_loss: 0.5487 - val_accuracy: 0.8031\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 9s 982ms/step - loss: 0.5446 - accuracy: 0.7890 - val_loss: 0.5184 - val_accuracy: 0.8164\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 9s 960ms/step - loss: 0.5153 - accuracy: 0.7964 - val_loss: 0.5055 - val_accuracy: 0.8164\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 9s 947ms/step - loss: 0.4981 - accuracy: 0.8031 - val_loss: 0.4876 - val_accuracy: 0.8252\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 9s 961ms/step - loss: 0.4745 - accuracy: 0.8124 - val_loss: 0.4841 - val_accuracy: 0.8230\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 9s 953ms/step - loss: 0.4520 - accuracy: 0.8156 - val_loss: 0.4624 - val_accuracy: 0.8429\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 9s 986ms/step - loss: 0.4329 - accuracy: 0.8237 - val_loss: 0.4565 - val_accuracy: 0.8496\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 9s 983ms/step - loss: 0.4156 - accuracy: 0.8326 - val_loss: 0.4452 - val_accuracy: 0.8473\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 9s 973ms/step - loss: 0.4001 - accuracy: 0.8373 - val_loss: 0.4318 - val_accuracy: 0.8473\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 9s 961ms/step - loss: 0.3868 - accuracy: 0.8609 - val_loss: 0.4247 - val_accuracy: 0.8673\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 9s 959ms/step - loss: 0.3728 - accuracy: 0.8656 - val_loss: 0.4216 - val_accuracy: 0.8496\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 9s 974ms/step - loss: 0.3648 - accuracy: 0.8648 - val_loss: 0.4090 - val_accuracy: 0.8562\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 9s 956ms/step - loss: 0.3525 - accuracy: 0.8717 - val_loss: 0.4163 - val_accuracy: 0.8562\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 9s 952ms/step - loss: 0.3450 - accuracy: 0.8757 - val_loss: 0.4046 - val_accuracy: 0.8628\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 9s 992ms/step - loss: 0.3390 - accuracy: 0.8769 - val_loss: 0.4166 - val_accuracy: 0.8518\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 9s 968ms/step - loss: 0.3431 - accuracy: 0.8668 - val_loss: 0.4110 - val_accuracy: 0.8628\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 9s 945ms/step - loss: 0.3322 - accuracy: 0.8781 - val_loss: 0.4029 - val_accuracy: 0.8562\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 9s 937ms/step - loss: 0.3276 - accuracy: 0.8808 - val_loss: 0.3999 - val_accuracy: 0.8606\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 9s 954ms/step - loss: 0.3230 - accuracy: 0.8794 - val_loss: 0.4004 - val_accuracy: 0.8628\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 9s 940ms/step - loss: 0.3194 - accuracy: 0.8804 - val_loss: 0.4012 - val_accuracy: 0.8628\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 9s 937ms/step - loss: 0.3181 - accuracy: 0.8818 - val_loss: 0.3948 - val_accuracy: 0.8628\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 9s 944ms/step - loss: 0.3124 - accuracy: 0.8843 - val_loss: 0.4061 - val_accuracy: 0.8650\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 9s 937ms/step - loss: 0.3093 - accuracy: 0.8877 - val_loss: 0.4018 - val_accuracy: 0.8673\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 9s 945ms/step - loss: 0.3060 - accuracy: 0.8836 - val_loss: 0.3956 - val_accuracy: 0.8717\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 9s 960ms/step - loss: 0.3052 - accuracy: 0.8890 - val_loss: 0.3961 - val_accuracy: 0.8717\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 9s 952ms/step - loss: 0.3051 - accuracy: 0.8845 - val_loss: 0.4030 - val_accuracy: 0.8650\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 9s 951ms/step - loss: 0.3057 - accuracy: 0.8843 - val_loss: 0.4094 - val_accuracy: 0.8628\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 9s 966ms/step - loss: 0.2986 - accuracy: 0.8853 - val_loss: 0.4013 - val_accuracy: 0.8606\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 9s 962ms/step - loss: 0.3019 - accuracy: 0.8855 - val_loss: 0.4001 - val_accuracy: 0.8628\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 9s 968ms/step - loss: 0.3012 - accuracy: 0.8897 - val_loss: 0.4013 - val_accuracy: 0.8695\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 9s 970ms/step - loss: 0.2939 - accuracy: 0.8885 - val_loss: 0.3960 - val_accuracy: 0.8650\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 9s 972ms/step - loss: 0.2919 - accuracy: 0.8912 - val_loss: 0.4036 - val_accuracy: 0.8650\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 9s 962ms/step - loss: 0.2895 - accuracy: 0.8900 - val_loss: 0.3959 - val_accuracy: 0.8717\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 9s 967ms/step - loss: 0.2887 - accuracy: 0.8929 - val_loss: 0.3999 - val_accuracy: 0.8673\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 9s 947ms/step - loss: 0.2864 - accuracy: 0.8912 - val_loss: 0.4087 - val_accuracy: 0.8650\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 9s 948ms/step - loss: 0.2873 - accuracy: 0.8936 - val_loss: 0.4060 - val_accuracy: 0.8650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fccc0f4dd50>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek2GUT_nBiG7",
        "outputId": "e1c170ed-c41a-4596-975e-5b5b94cc2329"
      },
      "source": [
        "loss, acc_treino = rede.evaluate(X_treino, y_treino, verbose=0)\n",
        "loss2, acc_teste = rede.evaluate(X_teste, y_teste, verbose=0)\n",
        "print(f'Acurácia no treino: {round(acc_treino*100, 2)}%')\n",
        "print(f'Acurácia no teste: {round(acc_teste*100, 2)}%')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no treino: 88.97%\n",
            "Acurácia no teste: 83.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T61i5sg5Da1g"
      },
      "source": [
        "predict = rede.predict(X_teste)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFdq0E3w_Gp1",
        "outputId": "d1bba511-c509-4e5c-de71-02b28216d27b"
      },
      "source": [
        "predict1 = np.argmax(predict, axis=1)\n",
        "\n",
        "y_teste1 = np.argmax(y_teste, axis=1)\n",
        "np.array(y_teste1.reshape(1,-1))[0]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 1, ..., 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9U9RC7H8q6Q",
        "outputId": "a93fd6ee-a5c1-4fc7-8d66-cd86e895bdb2"
      },
      "source": [
        "print(classification_report(y_teste1, predict1, labels=[0,1,2]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       923\n",
            "           1       0.84      0.85      0.84       864\n",
            "           2       0.90      0.60      0.72       148\n",
            "\n",
            "    accuracy                           0.84      1935\n",
            "   macro avg       0.86      0.77      0.81      1935\n",
            "weighted avg       0.84      0.84      0.84      1935\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "fbKfb8S8EiMZ",
        "outputId": "7448de0f-07c1-424c-fe47-9f4126514ec3"
      },
      "source": [
        "cm = confusion_matrix(y_teste1, predict1)\n",
        "sns.heatmap(cm , fmt=\".3g\", annot= True, cmap=\"Greens\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2wpqmotoR_w"
      },
      "source": [
        "#Referências"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53qIOjuTofIW"
      },
      "source": [
        "[1] Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013a).  Efficient estimation ofword representations in vector space.arXiv preprint arXiv:1301.3781. \\\\\n",
        "[2] Mikolov,  T.,  Sutskever,  I.,  Chen,  K.,  Corrado,  G. S.,  and Dean,  J. (2013b).   Distributed representations of words and phrases and their compositionality.  In Advances in neural information processing systems, pages 3111–3119. \\\\\n",
        "[3] Brownlee Jason(2017). https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/ - acesso em: 04/08/2021.  \\\\\n",
        "[4] Brownlee Jason(2017). https://machinelearningmastery.com/best-practices-document-classification-deep-learning/ - acesso em: 04/08/2021.  \\\\\n",
        "[5] Brownlee Jason(2017). https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/ - acesso em: 04/08/2021. \\\\"
      ]
    }
  ]
}