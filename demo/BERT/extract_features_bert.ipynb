{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"extract_features_bert.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1UYOxxNbfAs0kfOYctI1zJzKgdwkZJDsf","authorship_tag":"ABX9TyM95FSdmY0VbGKTN4QSWDTI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"XAwdgk92weMT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628818129946,"user_tz":180,"elapsed":15938,"user":{"displayName":"Projeto NLP","photoUrl":"","userId":"01502388222153845214"}},"outputId":"617f12ad-6adc-4119-9b35-8fe770e1f607"},"source":["!pip install unidecode\n","!pip install transformers==4.2.2\n","!pip install pyreadr\n","!pip install unidecode\n","!pip install ftfy\n","!pip install git+https://github.com/legalnlp21/legalnlp"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n","Requirement already satisfied: transformers==4.2.2 in /usr/local/lib/python3.7/dist-packages (4.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (4.6.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (0.0.45)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (21.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (1.19.5)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (0.9.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (3.0.12)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.2) (3.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.2) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.2.2) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (1.15.0)\n","Requirement already satisfied: pyreadr in /usr/local/lib/python3.7/dist-packages (0.4.2)\n","Requirement already satisfied: pandas>0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyreadr) (1.1.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>0.24.0->pyreadr) (2018.9)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>0.24.0->pyreadr) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>0.24.0->pyreadr) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>0.24.0->pyreadr) (1.15.0)\n","Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.0.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n","Collecting git+https://github.com/legalnlp21/legalnlp\n","  Cloning https://github.com/legalnlp21/legalnlp to /tmp/pip-req-build-kqwmck1c\n","  Running command git clone -q https://github.com/legalnlp21/legalnlp /tmp/pip-req-build-kqwmck1c\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from legalnlp==1.0.0) (6.0.3)\n","Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (from legalnlp==1.0.0) (3.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->legalnlp==1.0.0) (0.2.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ujI89yVCwbVN","executionInfo":{"status":"ok","timestamp":1628818132419,"user_tz":180,"elapsed":235,"user":{"displayName":"Projeto NLP","photoUrl":"","userId":"01502388222153845214"}}},"source":["from IPython.display import Image\n","from IPython.display import clear_output\n","import pickle\n","import random\n","import unidecode\n","import re\n","import ftfy\n","import os\n","import copy\n","import torch\n","import torch.nn as nn\n","import torch.utils.data as tdata\n","import torch.optim as optim\n","import transformers\n","from transformers import AutoModel, AutoTokenizer, AutoConfig\n","from transformers import BertForPreTraining, BertModel, BertTokenizer, BertForMaskedLM, BertForNextSentencePrediction, BertForQuestionAnswering\n","# manipulação numérica e de dataframes\n","import numpy as np\n","import pandas as pd\n","# gráficos e ajustes visuais\n","import matplotlib.pyplot as plt\n","import textwrap\n","from tqdm import tqdm"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"ulySGNf23lIy","executionInfo":{"status":"ok","timestamp":1628818136749,"user_tz":180,"elapsed":16,"user":{"displayName":"Projeto NLP","photoUrl":"","userId":"01502388222153845214"}}},"source":["from legalnlp.get_premodel import *\n","from legalnlp.clean_functions import *"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFyocCwQ43mI"},"source":["get_premodel('bert')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":414},"id":"NdMgDC3KvEeY","executionInfo":{"status":"ok","timestamp":1628818151930,"user_tz":180,"elapsed":985,"user":{"displayName":"Projeto NLP","photoUrl":"","userId":"01502388222153845214"}},"outputId":"0d18665c-b5fd-4505-8e59-070c1d45a9e1"},"source":["data=pd.read_csv('https://raw.githubusercontent.com/legalnlp21/legalnlp/main/demo/data_base.csv')\n","data.drop(columns=['Unnamed: 0'],inplace=True)\n","data['text'] = data['text'].apply(lambda x:clean_bert(x))\n","model = '/content/BERTikal (1)/BERTikal'\n","tokenizer= '/content/BERTikal (1)/BERTikal/vocab.txt'\n","data"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ofício Requisitório - Comunicação - Protocolo ...</td>\n","      <td>H:Arquivado</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Suspensão do Prazo Prazo referente ao usuário ...</td>\n","      <td>H:Ativo</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Certidão de Publicação Expedida Relação :0274/...</td>\n","      <td>H:Ativo</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Embargos de Declaração Juntados Nº Protocolo: ...</td>\n","      <td>H:Ativo</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Certidão de Trânsito em Julgado com Baixa Expe...</td>\n","      <td>H:Arquivado</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5088</th>\n","      <td>Petição Juntada Juntada a petição diversa - Ti...</td>\n","      <td>H:Ativo</td>\n","    </tr>\n","    <tr>\n","      <th>5089</th>\n","      <td>Suspensão do Prazo Prazo referente ao usuário ...</td>\n","      <td>H:Ativo</td>\n","    </tr>\n","    <tr>\n","      <th>5090</th>\n","      <td>Tipo do Movimento:Arquivamento Tipo de arquiva...</td>\n","      <td>H:Arquivado</td>\n","    </tr>\n","    <tr>\n","      <th>5091</th>\n","      <td>Ofício Juntado Juntada a petição diversa - Tip...</td>\n","      <td>H:Ativo</td>\n","    </tr>\n","    <tr>\n","      <th>5092</th>\n","      <td>Certidão de Não Consulta ao Teor da Informação...</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5093 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text        label\n","0     Ofício Requisitório - Comunicação - Protocolo ...  H:Arquivado\n","1     Suspensão do Prazo Prazo referente ao usuário ...      H:Ativo\n","2     Certidão de Publicação Expedida Relação :0274/...      H:Ativo\n","3     Embargos de Declaração Juntados Nº Protocolo: ...      H:Ativo\n","4     Certidão de Trânsito em Julgado com Baixa Expe...  H:Arquivado\n","...                                                 ...          ...\n","5088  Petição Juntada Juntada a petição diversa - Ti...      H:Ativo\n","5089  Suspensão do Prazo Prazo referente ao usuário ...      H:Ativo\n","5090  Tipo do Movimento:Arquivamento Tipo de arquiva...  H:Arquivado\n","5091  Ofício Juntado Juntada a petição diversa - Tip...      H:Ativo\n","5092  Certidão de Não Consulta ao Teor da Informação...          NaN\n","\n","[5093 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"ni35GXIxu7kq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"92a9894c-3657-4611-88de-f383903d3681"},"source":["def extract_features_bert(path_model, path_tokenizer, data,gpu=True):\n","    if gpu:\n","        device = torch.device('cuda')\n","        os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","        bert_tokenizer = BertTokenizer.from_pretrained(path_tokenizer, do_lower_case=False)\n","        bert_model = BertModel.from_pretrained(path_model).to(device)\n","        bert = data.apply(lambda x: bert_tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True))\n","        data_text = list(data)\n","        encoded_inputs = bert_tokenizer(data_text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n","        input_ids = encoded_inputs['input_ids'].to(device)\n","        clear_output()\n","        # Criando o nosso vetor de features\n","        features = []\n","    \n","        # Aplicando o modelo pré-treinado em cada frase e adicionando-o ao nosso vetor\n","    \n","        for i in tqdm(range(len(data)), mininterval=40, maxinterval=500):\n","    \n","            with torch.no_grad():\n","    \n","                last_hidden_states = bert_model(\n","                    input_ids[i:(i+1)])[1].cpu().numpy().reshape(-1).tolist()\n","            features.append(last_hidden_states)\n","    else:\n","        bert_tokenizer = BertTokenizer.from_pretrained(path_tokenizer, do_lower_case=False)\n","        bert_model = BertModel.from_pretrained(path_model)\n","        bert = data.apply(lambda x: bert_tokenizer.encode(\n","            x, add_special_tokens=True, max_length=512, truncation=True))\n","        encoded_inputs = bert_tokenizer(\n","            data_text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n","        input_ids = encoded_inputs['input_ids']\n","        # Criando o nosso vetor de features\n","        features = []\n","    \n","        # Aplicando o modelo pré-treinado em cada frase e adicionando-o ao nosso vetor\n","    \n","        for i in tqdm(range(len(data))):\n","    \n","            with torch.no_grad():\n","    \n","                last_hidden_states = bert_model(\n","                    input_ids[i:(i+1)])[1].cpu().numpy().reshape(-1).tolist()\n","            features.append(last_hidden_states)\n","    features = np.array(features)\n","    features[:2]\n","    df_features = pd.DataFrame(features)\n","    return df_features\n","\n","\n","\n","    # os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","    #device = torch.device('cuda:0')\n","features= extract_features_bert(model,tokenizer,data['text'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" 96%|█████████▌| 4884/5093 [03:20<00:08, 24.35it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"def2Xhv_ItWI"},"source":["features"],"execution_count":null,"outputs":[]}]}