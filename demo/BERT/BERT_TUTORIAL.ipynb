{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_TUTORIAL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UiST_osLMJLN",
        "YKswmOITHI9L",
        "QdpuvKK_QLtq",
        "2TbkubgI9Br6",
        "BrzvttrDzSu7"
      ],
      "authorship_tag": "ABX9TyOVMoQTeJ4gnUE1wpZN4IYV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/legalnlp21/legalnlp/blob/main/demo/BERT/BERT_TUTORIAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86buPegRZ5z_"
      },
      "source": [
        "from IPython.display import Image\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-owYaP70mSQ"
      },
      "source": [
        "def show(link,width):\n",
        "   return IPython.display.Image(data = link, width = width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcWsY0-BaAVH"
      },
      "source": [
        "# Introdução\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcuhPn6AaEuv"
      },
      "source": [
        "Com o amadurecimento das Redes Neurais Recorrentes (RNNs, em inglês), veio o surgimento e desenvolvimento de modelos de processamento de linguagem natural (PLN) mais complexos, capazes de compreender cada vez mais sentenças e seus contextos em um conjunto de textos. Como exemplo de uma aplicação dessas redes, temos o **BERT**, que é um modelo de aprendizado profundo bastante utilizado em diversas tarefas de processamento de linguagem natural.\n",
        "\n",
        "BERT significa **B**idirectional **E**ncoder **R**epresentations for **T**ransformers e foi desenvolvido por pesquisadores do $\\textit{Google AI Language}$ em 2018 e apresentado ao público em 2019, obtendo resultados espetaculares, conforme seu [artigo original](https://arxiv.org/pdf/1810.04805.pdf). Além disso, os [códigos do modelo](https://github.com/google-research/bert) também foram liberados pela equipe.\n",
        "\n",
        "Sendo utilizado ainda como inspiração em diversas arquiteturas de PLN, formas de treinamento e modelos de linguagem natural, como XLNet, ERNIE2.0, RoBERTa, entre outros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am1f10iCaVoT"
      },
      "source": [
        "##O que é o BERT e como funciona"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vFz-PqOSWq7"
      },
      "source": [
        "O que faz o BERT ser um modelo que se destaca é o fato dele utilizar um treinamento bidirecional do Transformer, que é um tipo de mecanismo de atenção muito efieciente que aprende as relações entre as componentes de um determinado texto.\n",
        "\n",
        "Os Transformers funcionam com dois mecanismos: o $\\textit{encoder}$ e o $\\textit{decoder}$. Basicamente, o encoder funciona transformando o input recebido em contexto e o decoder funciona transformando esse contexto em algum outro objetivo, como por exemplo a tradução para uma outra língua.\n",
        "\n",
        "Para mais informações sobre os Tranformers, leia o artigo original em que foi apresentado: [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf).\n",
        "\n",
        "\n",
        "Diferentemente dos modelos unidirecionais baseados em \"contexto livre\", como é o caso do $\\textit{word2vec}$, gerando um $\\textit{embedding}$ (representação do espaço das palavras no espaço real) igual para uma determinada palavra independentemente do seu contexto, o BERT, por ser um modelo bidirecional, consegue extrair o significado da palavra em cada contexto, por isso é chamado também de um \"modelo contextual\".\n",
        "\n",
        "Para exemplificar o parágrafo acima, pense na palavra \"banco\". Nos modelos livres de contexto, essa palavra teria a mesma representação independentemente do seu contexto, embora banco representando uma agência bancária é diferente do banco de uma praça, por exemplo. Por sua vez, os modelos baseados em contexto, identificam cada palavra em seu contexto.  [click here to acess slides form Stanford about BERT](https://nlp.stanford.edu/seminar/details/jdevlin.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJKjE3Qyz5Os",
        "outputId": "192471cf-1c45-424d-b65f-6ca51a6a0da7"
      },
      "source": [
        "show('https://raw.githubusercontent.com/legalnlp21/legalnlp/b7e2fcd4c4065bd1599f5ff0987d9581fb667d4c/demo/BERT/notebook_images/image1.jpg',600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c8b70028d821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/legalnlp21/legalnlp/b7e2fcd4c4065bd1599f5ff0987d9581fb667d4c/demo/BERT/notebook_images/image1.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-7692515c0a42>\u001b[0m in \u001b[0;36mshow\u001b[0;34m(link, width)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'IPython' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_cxmYXw0VBe"
      },
      "source": [
        "show('https://raw.githubusercontent.com/legalnlp21/legalnlp/main/demo/BERT/notebook_images/image2.jpg',600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MhPO3jM0M4K"
      },
      "source": [
        "Além disso, o BERT foi treinado utilizando uma enorme quantidade de dados não rotulados da Wikipedia (cerca de 2,5 bilhões de palavras) e em corpus de livros (cerca de 800 milhões de palavras).\n",
        "\n",
        "Agora veremos brevemente a arquitetura desse modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDJG3cafQ51J"
      },
      "source": [
        "##Arquitetura"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoRcRARcQ8EQ"
      },
      "source": [
        "Quanto à arquitetura, o BERT possui dois tipos, de acordo com o artigo citado acima: o Base e o Large. As diferenças estão listadas abaixo:\n",
        "\n",
        "**BERTBASE:** \n",
        "\n",
        "  * L = 12 \\\n",
        "  * H = 768 \\\n",
        "  * A = 12 \\\n",
        "  * Total de Parâmetros = 110 milhões\n",
        "\n",
        "**BERTLARGE:**\n",
        "\n",
        "  * L = 24 \\\n",
        "  * H = 1024 \\\n",
        "  * A = 16 \\\n",
        "  * Total de Parâmetros = 340 milhões\n",
        "\n",
        "\\\n",
        "**Onde**:\\\n",
        "    L = Número de camadas (Blocos Transformer)\\\n",
        "    H = Quantidade de unidades na rede neural\\\n",
        "    A = Cabeças de auto-atenção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-QnGtbW0gxB"
      },
      "source": [
        "show('https://raw.githubusercontent.com/legalnlp21/legalnlp/main/demo/BERT/notebook_images/bert1.jpg',600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJyT8Cp3hb99"
      },
      "source": [
        "### Entrada do Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-DHUwyxhePA"
      },
      "source": [
        "A entrada do modelo pode ser composta por uma sentença ou por um par de sentenças, com tamanho máximo suportado pelo modelo de 512 tokens. O BERT utiliza a tokenização WordPiece.\n",
        "\n",
        "O primeiro token de entrada é sempre marcado como [CLS], que é um token especial de classificação. Quando duas frases entram no modelo, elas podem ser diferenciadas por meio do token [SEP]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18U5ahxS2QUN"
      },
      "source": [
        "show('https://raw.githubusercontent.com/legalnlp21/legalnlp/main/demo/BERT/notebook_images/enconder1.jpg',600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhlgJxkx2mWv"
      },
      "source": [
        "show('https://raw.githubusercontent.com/legalnlp21/legalnlp/main/demo/BERT/notebook_images/enconder2.jpg',600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy-GA4lu14Zu"
      },
      "source": [
        "Para um dado token de entrada, sua forma é dada por um embedding da soma de 3 outros tokens, como visto na figura acima. São eles:\n",
        "\n",
        "* **Position Embeddings**: O modelo aprende e utiliza embeddings de posição para expressar a posição/ordem das palavras na sentença. \n",
        "\n",
        "* **Segment Embeddings**: O BERT recebe pares de sentenças e utiliza embeddings para o modelo aprender e conseguir distingui-las.  \n",
        "\n",
        "* **Token Embeddings**: São embeddings específicos, aprendidos através do vocabulário do WordPiece."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ-e2fKusHpj"
      },
      "source": [
        "### Saída do Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aHs8X5ZsLlC"
      },
      "source": [
        "Já a saída do modelo consiste em um vetor de tamanho $\\textit{hidden_size}$, que no caso do BERT BASE é 768 para cada token de entrada, que também pode ser visto como uma representação vetorial real daquele determinado token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6hRrVVjAiEB"
      },
      "source": [
        "## Pré Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goMCRE6XAkG2"
      },
      "source": [
        "O BERT possui 2 estratégias de pré treinamento: Masked Language Model (MLM) e Next Sentence Prediction (NSP)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wti5YhcECm_R"
      },
      "source": [
        "### **Masked LM (MLM)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2y55E72CqFh"
      },
      "source": [
        "Nessa abordagem, são mascarados ([MASK]) aleatoriamente $15\\%$ dos tokens de entrada e então feita a predição apenas desses tokens mascarados por meio de uma função $\\textit{softmax}$. \n",
        "\n",
        "Porém, surge um problema com essa abordagem: É criado um desbalanceamento entre a fase de pré-treinamento e a fase de ajuste-fino (fine-tuning), pois o token [MASK] não aparece na última. Para solucionar isso, é realizado, dentro dos $15\\%$ dos tokens aleatoriamente selecionados:\n",
        "\n",
        "\\\n",
        "* $80\\%$ das vezes é sustituído com [MASK]:\n",
        "\n",
        "$\\quad\\quad\\quad$ Fui ao banco $\\rightarrow$ Fui ao [MASK]\n",
        "\n",
        "\\\n",
        "* $10\\%$ das vezes é susbtituído com alguma palavra aleatória:\n",
        "\n",
        "$\\quad\\quad\\quad$ Fui ao banco $\\rightarrow$ Fui ao chovendo\n",
        "\n",
        "\\\n",
        "* $10\\%$ das vezes é mantido a mesma palavra\n",
        "\n",
        "$\\quad\\quad\\quad$ Fui ao banco $\\rightarrow$ Fui ao banco"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su5-ve--EV63"
      },
      "source": [
        "# example\n",
        "# Input Sequence  : The man went to [MASK] store with [MASK] dog\n",
        "# Target Sequence :                  the                his"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiST_osLMJLN"
      },
      "source": [
        "### **Next Sentence Prediction (NSP)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIvyDwkXMO0a"
      },
      "source": [
        "Essa estratégia, por sua vez, se caracteriza por focar nas relações entre as sentenças, pré-treinando assim para uma tarefa de predição de próximas sentenças em que são possíveis apenas 2 resultados, \"IsNext\", caso a sentença B seja a próxima sentença de A ou \"NotNext\" caso contrário.\n",
        "\n",
        "Para essa tarefa, os dados de treino consistem de $50\\%$ dos dados rotulados como \"IsNext\" e os outros $50\\%$ como \"NotNext\", e é aplicada em conjunto com a estratégia de Masked ML explicada acima."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUfWL1aoJaBd"
      },
      "source": [
        "Exemplos:\n",
        "\n",
        "Input = [CLS] the man went to [MASK] store [SEP]\n",
        "he bought a gallon [MASK] milk [SEP]\n",
        "\n",
        "Label = IsNext\n",
        "\n",
        "Input = [CLS] the man [MASK] to the store [SEP]\n",
        "penguin [MASK] are flight ##less birds [SEP]\n",
        "\n",
        "Label = NotNext\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vDvFQfyRO1U"
      },
      "source": [
        "# Utilizando o BERT: **Fine-Tuning** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcOzTxZvRY1r"
      },
      "source": [
        "Classificação de Pares de Sentenças — É semelhante ao processo de Next Sentence Prediction (NSP), adicionando uma camada de classificação no topo do output referente ao token [CLS] retornando uma distribuição de probabilidades calculadas por uma função $\\textit{softmax}$. \n",
        "\n",
        "Classificação de Sentenças Únicas — Semelhante ao processo acima. \n",
        "\n",
        "Single Sentence Tagging Task — Nessa tarefa são preditas tags para um determinado token. Como exemplo, para uma tarefa de classificar partes do discurso em Pronome, Verbo, Adjetivo, etc. \n",
        "\n",
        "Question Answering Tasks — Essa é uma tarefa de predição. O modelo recebe uma pergunta, que atua como a primeira sentença e um parágrafo contendo o contexto relacionado a pergunta, atuando como a segunda sentença. É feito então o produto escalar da forma final do embedding de cada token com um vetor de pesos, sendo aplicado em uma função de ativação para retornar uma distribuição de probabilidade. Segue um link com mais informações sobre: [https://mccormickml.com/2020/03/10/question-answering-with-a-fine-tuned-BERT/](https://mccormickml.com/2020/03/10/question-answering-with-a-fine-tuned-BERT/) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGjPbzinPxab"
      },
      "source": [
        "#Mão na Massa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKswmOITHI9L"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8jG9pqj3thm"
      },
      "source": [
        "Instalando as bibliotecas necessárias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H20N1cso31zC"
      },
      "source": [
        "!pip install unidecode\n",
        "!pip install ftfy\n",
        "!pip install transformers==4.2.2\n",
        "!pip install pyreadr\n",
        "!pip install git+https://github.com/legalnlp21/legalnlp\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL5-IFzvxHhL"
      },
      "source": [
        "Aqui vamos importar algumas bibliotecas que serão muito úteis para frente!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq6V2tDZI0x8"
      },
      "source": [
        "# manipulação numérica e de dataframes\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# gráficos e ajustes visuais\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import textwrap\n",
        "from tqdm import tqdm\n",
        "\n",
        "# pré-processamento de textos e lidar com variáveis categóricas, modelos e métricas \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# tratamento de textos \n",
        "import unidecode\n",
        "import re\n",
        "import ftfy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8h8RGt3SFIA"
      },
      "source": [
        "# If you want to use Google drive for get data, use this code\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "#data=pd.read_csv('/content/gdrive/MyDrive/data_base.csv')\n",
        "#data.drop(columns=['Unnamed: 0'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNfZlG8CJE5b"
      },
      "source": [
        "# Code for get data from github\n",
        "data=pd.read_csv('https://raw.githubusercontent.com/legalnlp21/legalnlp/main/demo/data_base.csv')\n",
        "data.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "data.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdpuvKK_QLtq"
      },
      "source": [
        "## Breve exploração na base de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2xU7K-6xQIe"
      },
      "source": [
        "Antes de aplicar os modelos, vale a pena dar uma explorada nos dados que estamos trabalhando. Primeiramente, qual o tamanho desse conjunto de dados?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in9zK0pXxim2"
      },
      "source": [
        "print(\"Quantidade de linhas: \", data.shape[0])\n",
        "print(\"Quantidade de colunas: \", data.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ft1fRf9x2qN"
      },
      "source": [
        "Vamos visualizar uma pequena amostra desses dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHG1hRhow4_F"
      },
      "source": [
        "# amostra de tamanho 5\n",
        "data.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpecX-pNyK5-"
      },
      "source": [
        "Vamos verificar se tem algum valor faltante nas colunas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY9LxHbC7213"
      },
      "source": [
        "# valores nas colunas faltante\n",
        "print(f'Total de: {data[\"text\"].isna().sum()} textos vazios')\n",
        "print(f'Total de: {data[\"label\"].isna().sum()} classes vazias')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ogl5M1DygS8"
      },
      "source": [
        "Aqui um gráfico de como os rótulos da coluna \"label\" estão distribuídos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNfwYV91JqWi"
      },
      "source": [
        "# countplot das labels\n",
        "sns.countplot(x = data['label'])\n",
        "\n",
        "plt.xticks(np.arange(0, 3, step = 1), ['Arquivado', 'Ativo', 'Não Ativo'])\n",
        "plt.xlabel('Status')\n",
        "plt.ylabel('Quantidade')\n",
        "plt.title('Status countplot')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g76QyAEzNj6"
      },
      "source": [
        "E em frequências relativas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j73ryhTCyk9p"
      },
      "source": [
        "# Frequência das labels\n",
        "freq = pd.DataFrame(data['label'].value_counts()/len(data))\n",
        "freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TbkubgI9Br6"
      },
      "source": [
        "##Limpando os textos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YzICwOuEC81"
      },
      "source": [
        "Aqui vamos aplicar a função abaixo (clean_bert), que recebe um texto como argumento e realiza a limpeza desse texto, cuidando de Unicodes ruins (caracteres estranhos) por meio do atributo fix_text da biblioteca [ftfy: fixes text for you](https://ftfy.readthedocs.io/en/latest/) e fazendo substituições de determinados caracteres para outros específicos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb50kJAS_1GP"
      },
      "source": [
        "from legalnlp.clean_functions import clean_bert\n",
        "\n",
        "'''\n",
        "def clean_bert(texto):   \n",
        "    result = ftfy.fix_text(texto)\n",
        "    result=result.replace(\"nº\", \"\" )\n",
        "    result=result.replace(\"n.º\" ,\"\" )\n",
        "    result=result.replace(\"n°\", \"\")\n",
        "    result=result.replace(\"lei estadual nº \", \"lei\") \n",
        "    result=result.replace(\"lei federal nº \", \"lei\") \n",
        "    result=result.replace(\"lei municipal nº \", \"lei\")\n",
        "    result=result.replace(\"fl.\", \"fls.\")\n",
        "    result=result.replace(\"p.\", \"pp.\")\n",
        "    result=result.replace(\"art.\", \"artigo\")\n",
        "    result=result.replace(\"\\n\", \" \")\n",
        "    result=result.replace(\"dr\", \"dr.\")\n",
        "    result=result.replace(\"dra\", \"dr.\")\n",
        "    result=result.replace(\"ª\", \"\")\n",
        "    result=result.replace(\"º\", \"\")\n",
        "    result=result.replace(\"°\", \"\")\n",
        "    result=result.replace(\":\", \" : \") \n",
        "    result=re.sub(' +', ' ', result)\n",
        "    \n",
        "    return(result)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28yDf4zhFWId"
      },
      "source": [
        "Com a função clean_bert, aplicamos na coluna de textos do nosso conjunto de dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ5P4VeyCTw_"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x:clean_bert(x))\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygwPzZkb9jeJ"
      },
      "source": [
        "Após a limpeza dos dados, vamos dar uma olhada em alguns exemplos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlmyxCMv9i_z"
      },
      "source": [
        "str(data.loc[3, 'text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT6TxRcg-OL2"
      },
      "source": [
        "str(data.loc[1278, 'text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRmFU3wmE36f"
      },
      "source": [
        "#Aplicando o Label Enconder para deixar o target com valores númericos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbpDsfiZGGGg"
      },
      "source": [
        "Agora, com os textos limpos, vamos ver brevemente como lidar com as variáveis categóricas através do LabelEnconder: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9K_PKu4vNDP"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(data['label'])\n",
        "data['encoded'] = encoder.transform(data['label'])\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuKS1fcsN_yM"
      },
      "source": [
        "A coluna 'encoded' representa a forma que os elementos da coluna 'label' foram transformados em variáveis numéricas, como temos 3 classes, cada uma recebeu um valor 0, 1 ou 2, como podemos ver abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaFe4eU9_DLm"
      },
      "source": [
        "data.loc[[0, 1, 5], ['label', 'encoded']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-UscTSdwnl3"
      },
      "source": [
        "#Aplicando o tokenizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtoyztVNVojQ"
      },
      "source": [
        "O processo de tokenização é o processo de divisão do texto a fim de identificarmos as diferentes palavras das quais ele é formado. No caso do BERT, temos um tokenizador próprio que além de focar na identificação de cada palavra do textos, também há um processo de reconhecimento de palavras que não estão no nosso vocabulário propriamente dito, o que é feito por meio da divisão dessas palavras na tokenização, de tal forma que um palavra pode gerar mais de um token. Dessa maneira, o modelo pode aprender as partes dessa palavra e baseado no contexto em que ela está inserada e no contexto de outras palavras que possuam tokens em comum com ela é possível \"aprender seu significado\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9p1LsZnwqAl"
      },
      "source": [
        "import pickle\n",
        "import random\n",
        "import os\n",
        "import copy \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as tdata\n",
        "import torch.optim as optim\n",
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "from transformers import BertForPreTraining, BertModel, BertTokenizer, BertForMaskedLM, BertForNextSentencePrediction, BertForQuestionAnswering\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMuVyksyzJ9Y"
      },
      "source": [
        "# verificando se tem cuda disponível\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "device = torch.device('cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrzvttrDzSu7"
      },
      "source": [
        "## Loading Tokenizer and PreTrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX-hMkh845m1"
      },
      "source": [
        "link2 interessante: [Bert - Transformers Documentation](https://huggingface.co/transformers/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phDfntkR7gEB"
      },
      "source": [
        "Aqui vamos criar duas variáveis que servirão como o tokenizador e o modelo BERT que foi pré-treinado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsNBUeTEQVoc"
      },
      "source": [
        "from legalnlp.get_premodel import *\n",
        "# Fazendo o download do modelo pre-treinado BERTikal e o seu tokenizador\n",
        "get_premodel('bert')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7gyDFE_zVbc"
      },
      "source": [
        "%%time\n",
        "\n",
        "bert_model =  BertModel.from_pretrained('/content/BERTikal/BERTikal').to(device)\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('/content/BERTikal/BERTikal/vocab.txt', do_lower_case=False)\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLp13bvi7wUk"
      },
      "source": [
        "Aqui as configurações do modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdYtbQAy6cSK"
      },
      "source": [
        "# configuração do BERT\n",
        "bert_model.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpqYLuVkV60y"
      },
      "source": [
        "# Usando o tokenizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRhLI6Em8Fnq"
      },
      "source": [
        "Nessa seção veremos como o tokenizador importado acima funciona com alguns exemplos, relacionando com a teoria apresentada no começo desse tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvrAm8Y2A2Uj"
      },
      "source": [
        "Links interessantes sobre o BERT:\n",
        "https://nlpiation.medium.com/how-to-use-huggingfaces-transformers-pre-trained-tokenizers-e029e8d6d1fa\n",
        "\n",
        "http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLw1S2z6A_lz"
      },
      "source": [
        "# Exemplo 1\n",
        "print(bert_tokenizer.tokenize('Example to test the text tokenizer'))\n",
        "print()\n",
        "\n",
        "# Exemplo 2\n",
        "print(bert_tokenizer.encode('Another example with the tokenizer'))\n",
        "print(bert_tokenizer.decode(bert_tokenizer.encode('Another example with the tokenizer')))\n",
        "print()\n",
        "\n",
        "# Exemplo 3\n",
        "tokens = bert_tokenizer.tokenize(\"This is a sample text to test the tokenizer.\")\n",
        "print(bert_tokenizer.convert_tokens_to_ids(tokens))\n",
        "print(bert_tokenizer.decode(bert_tokenizer.convert_tokens_to_ids(tokens)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfTYJVWM2oaS"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids(['[CLS]', '[SEP]'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7Ia478J2RPG"
      },
      "source": [
        "# Tamaho do vocabulário\n",
        "print(\"Vocab size: \", bert_tokenizer.vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYOnrLcECltx"
      },
      "source": [
        "bert = data['text'].apply(lambda x: bert_tokenizer.encode(x, add_special_tokens=True,max_length=512, truncation = True))\n",
        "print('Max sentence length: ', max([len(sen) for sen in bert]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ob6jeHKB1WM"
      },
      "source": [
        "# Transformando nossos dados em tensores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3p_GFixVxiT"
      },
      "source": [
        "## Escrever texto aqui "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck21AQ8RGAZg"
      },
      "source": [
        "# Fazendo a padronização dos textos\n",
        "wrapper = textwrap.TextWrapper()\n",
        "data_text = list(data['text'])\n",
        "\n",
        "for text in range(len(data_text[:4])):\n",
        "  print(f'{wrapper.fill(data_text[text])}')\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs26gMieGO-g"
      },
      "source": [
        "# Aplicando o bert_tokenizer em nosso dataset com um comprimento máximo de 512 tokens\n",
        "encoded_inputs = bert_tokenizer(data_text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "#Agora temos nossos encoded_input em um dicionário com 3 chaves\n",
        "encoded_inputs.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_w_7Qj6nJSm"
      },
      "source": [
        "#Visualiando o primeiro texto após a aplicação do tokenizador\n",
        "print(encoded_inputs['input_ids'][0])\n",
        "\n",
        "print()\n",
        "\n",
        "# Mostrando o mesmo texto decodificado \n",
        "print(wrapper.fill(bert_tokenizer.decode(encoded_inputs['input_ids'][0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB05mU98IRI8"
      },
      "source": [
        "# Enviando os tensores para para a GPU\n",
        "input_ids = encoded_inputs['input_ids'].to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsf4vruMIwPm"
      },
      "source": [
        "# Criando o nosso vetor de features \n",
        "features = []\n",
        "\n",
        "# Aplicando o modelo pré-treinado em cada frase e adicionando-o ao nosso vetor\n",
        "\n",
        "for i in tqdm(range(len(data_text))):\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "      last_hidden_states = bert_model(input_ids[i:(i+1)])[1].cpu().numpy().reshape(-1).tolist()\n",
        "\n",
        "    features.append(last_hidden_states)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKK-MN4PVYtr"
      },
      "source": [
        "# Criando um numpy array com as features extraidas\n",
        "features = np.array(features)\n",
        "features[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syx5bus-V2OF"
      },
      "source": [
        "# Printando o numero de linhas e de colunas das features extraídas\n",
        "print('Número de linhas: ', features.shape[0])\n",
        "print('Número de colunas: ', features.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha4UpsIvJFrp"
      },
      "source": [
        "#Splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wsac6uRaBPt"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv6dDOjgahCT"
      },
      "source": [
        "features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1gN2_4VZwuH"
      },
      "source": [
        "df_features = pd.DataFrame(features)\n",
        "features_label = pd.concat([df_features, data['encoded']], axis = 1)\n",
        "features_label.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy-nkVge5QTy"
      },
      "source": [
        "features_label.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d-eEWJc2fbe"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(features_label.drop(columns = ['encoded']), features_label['encoded'], random_state = 42,test_size = 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU7Aepou-cWS"
      },
      "source": [
        "# Tamanhos dos x e y de treino e teste\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arI885saAgFk"
      },
      "source": [
        "#Classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khspgnN90Upj"
      },
      "source": [
        "## O Modelo de Regressão Logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWXKQAIbCmeL"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import loguniform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc3_E1CsAkp7"
      },
      "source": [
        "# Instanciando o modelo de Regressão Logística em que será feito o cross-validaton em seguida\n",
        "log_reg = LogisticRegression(max_iter = 10000,\n",
        "                             random_state = 42, \n",
        "                             solver = 'liblinear')\n",
        "\n",
        "log_reg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC4smhG0YV1b"
      },
      "source": [
        "y_train\n",
        "#y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsOakoO-Cxsh"
      },
      "source": [
        "# Definindo o espaço de busca de parâmetros\n",
        "space = dict()\n",
        "space['solver'] = ['liblinear']\n",
        "space['penalty'] = ['l1'] #, 'l2'\n",
        "space['C'] = np.logspace(-3, 3, 100)\n",
        "\n",
        "rscv = RandomizedSearchCV(log_reg, space, cv = 3, n_jobs = -1, verbose = 1, random_state = 42, n_iter = 30)\n",
        "\n",
        "# Fazendo o cross-validation\n",
        "result = rscv.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MB4IUzsKhdX"
      },
      "source": [
        "# Melhores hiperparâmetros\n",
        "print('Best Score: %s' % result.best_score_)\n",
        "print('Best Hyperparameters: %s' % result.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DXS_fhqKq3l"
      },
      "source": [
        "log_reg = LogisticRegression(penalty = result.best_params_['penalty'],\n",
        "                             C = result.best_params_['C'],\n",
        "                             solver = result.best_params_['solver'],\n",
        "                             random_state = 42)\n",
        "\n",
        "# Treinando os modelos com os melhores hiperparâmetros\n",
        "log_reg.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vgc0zI3A33c"
      },
      "source": [
        "# y hat - predicted values for y\n",
        "y_pred = log_reg.predict(x_test)\n",
        "y_pred[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycYVDCZWBlBy"
      },
      "source": [
        "# Prevendo as probabilidades \n",
        "log_reg.predict_proba(x_test)[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOGMXfAEMRwm"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCQFgB2iMU82"
      },
      "source": [
        "y_pred_train = log_reg.predict(x_train)\n",
        "y_pred_train[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeBZRYxKMcHN"
      },
      "source": [
        "# Acurácia\n",
        "accuracy_score(y_train, y_pred_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_5j8g48q4X_"
      },
      "source": [
        "# Plotando a matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot = True, cmap = 'Greens', fmt = '.3g')\n",
        "plt.title(\"Heatmap\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8qi-H3oucm6"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsZQ6vAo9zNa"
      },
      "source": [
        "## O Modelo de Boosting: CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6sSiZ9MNNqu"
      },
      "source": [
        "Links de exemplo de aplição do CatBoost: \n",
        "\n",
        "https://github.com/catboost/tutorials\n",
        "\n",
        "https://github.com/catboost/tutorials/blob/master/classification/classification_tutorial.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu7mfgz_Drfv"
      },
      "source": [
        "Link a respeito de validação:\n",
        "https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wXF1SAB0_41"
      },
      "source": [
        "Nesa seção vamos aplicar um modelo chamado CatBoost (Categorical Boosting), que é um modelo de aprendizado por comitê (ensemble learning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDkioOPwP2b"
      },
      "source": [
        "!pip install catboost\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFuGg3Fl_TtB"
      },
      "source": [
        "# Importando o CatBoostClassifier \n",
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jbhEnrnNY-u"
      },
      "source": [
        "# creating validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, stratify = y_train, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYVahG36d4Y-"
      },
      "source": [
        "tunned_model = CatBoostClassifier(\n",
        "    loss_function = 'MultiClass',\n",
        "#    thread_count = -1, \n",
        "    random_seed=42,\n",
        "#    iterations=3000,\n",
        "#    l2_leaf_reg=3,\n",
        "#    bagging_temperature=1,\n",
        "#    random_strength=1,\n",
        "#    leaf_estimation_method='Newton'\n",
        ")\n",
        "\n",
        "tunned_model.fit(\n",
        "    x_train, y_train,\n",
        "    verbose=500,\n",
        "    eval_set=(x_val, y_val),\n",
        "    early_stopping_rounds = 100\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5dWYb8bhr4j"
      },
      "source": [
        "y_cat_pred = tunned_model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkVrr31jhyOb"
      },
      "source": [
        "accuracy_score(y_test, y_cat_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO-ficbleLd7"
      },
      "source": [
        "tunned_model.predict_proba(x_test)[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jekdhPrrtSYk"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_cat_pred)\n",
        "sns.heatmap(cm, annot = True, cmap = 'Greens', fmt = '.3g')\n",
        "plt.title(\"Heatmap\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLKu3kC0tSYt"
      },
      "source": [
        "print(classification_report(y_test, y_cat_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}